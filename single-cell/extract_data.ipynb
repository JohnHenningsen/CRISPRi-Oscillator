{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filepaths need to be adjusted, maybe some minor refactoring bugs left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "from skimage import io\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_3ch(folder_path, path_BF, flip_upside_down=False):\n",
    "    \n",
    "    FI_folder_path = os.path.join(folder_path, 'FI')\n",
    "    SEG_folder_path = os.path.join(folder_path, 'SEG')\n",
    "    file_name_FI = path_BF.split(sep='\\\\')[-1][:-6] + 'FI.tif'\n",
    "    path_FI = os.path.join(FI_folder_path, file_name_FI)\n",
    "    try:\n",
    "        file_name_SEG = path_BF.split(sep='\\\\')[-1][:-4] + '_SEG.tiff'\n",
    "        path_SEG = os.path.join(SEG_folder_path, file_name_SEG)\n",
    "        mask_bin = io.imread(path_SEG)\n",
    "    except:\n",
    "        file_name_SEG = path_BF.split(sep='\\\\')[-1][:-7] + '_SEG.tiff'\n",
    "        path_SEG = os.path.join(SEG_folder_path, file_name_SEG)\n",
    "        mask_bin = io.imread(path_SEG)\n",
    "    \n",
    "    im_fi = np.squeeze(io.imread(path_FI))\n",
    "    # add [::2] if FI only every second frame\n",
    "    im_bf = np.squeeze(io.imread(path_BF))\n",
    "    mask_bin[mask_bin==2] = 0\n",
    "    mask_bin[mask_bin==3] = 0\n",
    "    mask_bin = mask_bin.astype(bool)\n",
    "    T = im_fi.shape[0]\n",
    "    \n",
    "    if flip_upside_down:\n",
    "        im_fi = im_fi[:,::-1,:]\n",
    "        im_bf = im_bf[:,::-1,:]\n",
    "        mask_bin = mask_bin[:,::-1,:]\n",
    "    \n",
    "    return im_fi, im_bf, mask_bin, T\n",
    "\n",
    "# frame extraction function\n",
    "def frame_extract(t):\n",
    "    # process and label mask\n",
    "    mask_proc = morphology.binary_erosion(mask_bin[t])\n",
    "    #mask_proc = morphology.binary_erosion(mask_proc)\n",
    "    mask_proc = morphology.convex_hull_object(mask_proc)\n",
    "    mask_proc = morphology.binary_erosion(mask_proc)\n",
    "    #mask_proc = morphology.opening(mask_proc)\n",
    "    mask_label, num_features = ndimage.label(mask_proc)\n",
    "\n",
    "    # extract centroid, area\n",
    "    area = np.zeros_like(range(num_features))\n",
    "    coord = np.zeros((2,num_features))\n",
    "    for i in range(num_features):\n",
    "        area[i] = len(mask_proc[mask_label==i+1].flatten())\n",
    "        coord_tuple = ndimage.center_of_mass(mask_bin[t], mask_label, i+1)\n",
    "        coord[0,i] = coord_tuple[0]\n",
    "        coord[1,i] = coord_tuple[1]\n",
    "    labels = np.arange(1,num_features+1)\n",
    "    dic_frame = {'label':labels, 'area':area, 'coordx':coord[0], 'coordy':coord[1]}\n",
    "    df_frame = pd.DataFrame(dic_frame, columns = ['label', 'area', 'coordx', 'coordy'])\n",
    "\n",
    "    # find mother cell\n",
    "    treshold = 50 # pixels\n",
    "    area_index = df_frame[df_frame['area'] < treshold].index\n",
    "    df_frame.drop(area_index, inplace=True) # filter by area\n",
    "    # exctract mother cell data\n",
    "    try:\n",
    "        mother_label = df_frame.set_index('label')['coordx'].idxmax() # highest x coord is mother cell        \n",
    "        mask_mother = mask_bin[t].astype(int)\n",
    "        mask_mother[mask_label==mother_label] = 2\n",
    "    \n",
    "\n",
    "        # optional: verification with plot\n",
    "        if t in verify_frames:\n",
    "            plt.figure(figsize=(10,10))\n",
    "            plt.subplot(131)\n",
    "            plt.imshow(im_bf[t], cmap='Greys')\n",
    "            plt.title('BF')\n",
    "            plt.subplot(132)\n",
    "            plt.imshow(im_fi[t], cmap='Greys')\n",
    "            plt.title('FI')\n",
    "            plt.subplot(133)\n",
    "            plt.imshow(mask_mother)\n",
    "            plt.title('Mask')\n",
    "            plt.savefig(str(sample_name) + '_t' + str(t) + '_verify.png', dpi=300)\n",
    "    \n",
    "        # extract FI\n",
    "        fi_mean = np.mean(im_fi[t][mask_mother==2].flatten())\n",
    "        fi_std = np.std(im_fi[t][mask_mother==2].flatten())\n",
    "        mother_area = df_frame.set_index('label').loc[mother_label]['area']\n",
    "        mother_coordx = df_frame.set_index('label').loc[mother_label]['coordx']\n",
    "        mother_coordy = df_frame.set_index('label').loc[mother_label]['coordy']\n",
    "        \n",
    "    except ValueError:\n",
    "        print('No mother cell found for file ' + str(sample_name) + ' frame ' + str(t), end='\\r')\n",
    "        fi_mean = np.nan\n",
    "        fi_std = np.nan\n",
    "        mother_area = np.nan\n",
    "        mother_coordx = np.nan\n",
    "        mother_coordy = np.nan\n",
    "        \n",
    "    # exctract SECOND mother cell value\n",
    "    try:\n",
    "        mother2_label = df_frame.set_index('label').drop(mother_label)['coordx'].idxmax() # second highest x coord is 2nd mother cell    \n",
    "        mask_mother = mask_bin[t].astype(int)\n",
    "        mask_mother[mask_label==mother2_label] = 3\n",
    "        # extract FI\n",
    "        fi2_mean = np.mean(im_fi[t][mask_mother==3].flatten())\n",
    "        fi2_std = np.std(im_fi[t][mask_mother==3].flatten())\n",
    "        mother2_area = df_frame.set_index('label').loc[mother2_label]['area']\n",
    "        mother2_coordx = df_frame.set_index('label').loc[mother2_label]['coordx']\n",
    "        mother2_coordy = df_frame.set_index('label').loc[mother2_label]['coordy']\n",
    "    except ValueError:\n",
    "        print('No 2nd mother cell found for file ' + str(sample_name) + ' frame ' + str(t), end='\\r')\n",
    "        fi2_mean = np.nan\n",
    "        fi2_std = np.nan\n",
    "        mother2_area = np.nan\n",
    "        mother2_coordx = np.nan\n",
    "        mother2_coordy = np.nan\n",
    "    except UnboundLocalError: # first mother cell not found\n",
    "        fi2_mean = np.nan\n",
    "        fi2_std = np.nan\n",
    "        mother2_area = np.nan\n",
    "        mother2_coordx = np.nan\n",
    "        mother2_coordy = np.nan        \n",
    "\n",
    "    # extract value of background (channel/bright and PDMS/dark)\n",
    "    roi_channel = np.zeros_like(im_fi[t])\n",
    "    roi_PDMS = np.zeros_like(im_fi[t])\n",
    "    roi_channel[0:50,:] = 1\n",
    "    roi_PDMS[-100:-1,0:25] = 1\n",
    "    roi_PDMS[-100:-1,-25:-1] = 1\n",
    "    fi_channel_mean = np.mean(im_fi[t][roi_channel==1].flatten())\n",
    "    fi_channel_std = np.std(im_fi[t][roi_channel==1].flatten())\n",
    "    fi_PDMS_mean = np.mean(im_fi[t][roi_PDMS==1].flatten())\n",
    "    fi_PDMS_std = np.std(im_fi[t][roi_PDMS==1].flatten())\n",
    "    \n",
    "    dic_fi = {'frame':t, \\\n",
    "             'FI':fi_mean, 'FIstd':fi_std, 'area':mother_area, 'coord_x':mother_coordx, 'coord_y':mother_coordy, \\\n",
    "             'FI2':fi2_mean, 'FI2std':fi2_std, 'area2':mother2_area, 'coord2_x':mother2_coordx, 'coord2_y':mother2_coordy, \\\n",
    "             'FIchannel':fi_channel_mean, 'FIchannelstd':fi_channel_std, 'FIpdms':fi_PDMS_mean, 'FIpdmsstd':fi_PDMS_std}\n",
    "    return dic_fi\n",
    "    \n",
    "# main loop\n",
    "def analyse_tifs():\n",
    "    row_list = []\n",
    "    for t in range(T):\n",
    "        dic_fi = frame_extract(t)\n",
    "        row_list.append(dic_fi)\n",
    "    df_results = pd.DataFrame(row_list, columns = ['frame', 'FI', 'FIstd', 'area', 'coord_x', 'coord_y', 'FI2', 'FI2std', 'area2', 'coord2_x', 'coord2_y', \\\n",
    "                                                   'FIchannel', 'FIchannelstd', 'FIpdms', 'FIpdmsstd'])\n",
    "    #df_results.to_csv(str(sample_name) + '.csv', index=False)\n",
    "    return df_results\n",
    "\n",
    "def background_correction(FIchannel, FIpdms, pdms_only = False):\n",
    "    # todo: automatically detect high variation or buildup in feed channel\n",
    "    if pdms_only:\n",
    "        background = FIpdms\n",
    "    else:\n",
    "        background = np.mean(np.stack([FIchannel ,FIpdms]), axis=0)\n",
    "    correction = background/np.mean(background)\n",
    "    return correction\n",
    "\n",
    "def comp_cutoff(area, diff_crit, length_crit):\n",
    "    area_diff = np.diff(area)\n",
    "    diff_condition = np.abs(area_diff) < diff_crit\n",
    "    condition_labeled, num_features = ndimage.label(diff_condition)\n",
    "    # filter out short regions with no change in area\n",
    "    filtered_condition = np.copy(condition_labeled)\n",
    "    for i in range(num_features):\n",
    "        length = len(condition_labeled[condition_labeled==i+1].flatten())\n",
    "        if length < length_crit:\n",
    "            filtered_condition[condition_labeled==i+1] = 0\n",
    "    try:\n",
    "        cutoff = np.min(np.argwhere(filtered_condition > 0))\n",
    "    except:\n",
    "        # no region that satisfies criteria\n",
    "        return None\n",
    "    return cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 1\n",
    "- input tif videos of cropped to seperate channels, with folder for brightfield (BF), GFP fluorescence intensity (FI) and segmentation output from ilastik (SEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "folder_path = '../191120_split' \n",
    "verify_frames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- process videos and output csv table for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over all tifs in folder_path, assume subfolder structure (BF, FI and SEG) and specific filenames\n",
    "BF_folder_path = os.path.join(folder_path, 'BF')\n",
    "BF_list = [i for i in glob.glob(os.path.join(BF_folder_path, '*.tif'))]\n",
    "\n",
    "# first iterate over BF tifs, then open corresponding FI and SEG\n",
    "i = 1\n",
    "interrupt = 1000\n",
    "for path_BF in BF_list:\n",
    "    if i > interrupt:\n",
    "        sys.exit( 0 )\n",
    "    print('\\n%i out of %i' % (i, len(BF_list)))\n",
    "    sample_name = '191120' + path_BF.split(sep='\\\\')[-1][4:-7]\n",
    "    im_fi, im_bf, mask_bin, T = open_3ch(folder_path, path_BF)\n",
    "    # execute main process\n",
    "    df = analyse_tifs()\n",
    "    df['name'] = str(sample_name)\n",
    "    df['id'] = i\n",
    "    # save CSV\n",
    "    out_path = os.path.join(folder_path, 'CSV', str(sample_name)) + '.csv'\n",
    "    df.to_csv(out_path, index=False)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- open csv tabes of individual channels, process and summarize in single csv table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder_path = '../191120_proc/5_data/CSV' \n",
    "csv_files = [i for i in glob.glob(os.path.join(csv_folder_path, '*.csv'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add time vector (extracted from metadata in seperate script, index shift issue with this specific dataset) to dataframe\n",
    "df_time = pd.read_csv('data/191120_time_vectors.csv')\n",
    "t_pre = df_time['t_pre'].values[:-1]\n",
    "t_post = df_time['t_post'].values[:-1]\n",
    "\n",
    "for path in csv_files:\n",
    "    pos = int(path.split(sep='\\\\')[-1][10:12])\n",
    "    table = pd.read_csv(path, skiprows=0)\n",
    "    if pos < 9:\n",
    "        table['t'] = t_pre\n",
    "    if pos >= 9:\n",
    "        table['t'] = t_post\n",
    "    table.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sep=, to csv files to open them easily in Excel\n",
    "#print('sep=, added to the following files:')\n",
    "#for file_name in csv_files:\n",
    "#    with open(file_name, 'r') as fin:\n",
    "#        content = fin.read().splitlines(True)\n",
    "#    with open(file_name, 'w') as fout:\n",
    "#        if content[0] != 'sep=,\\n':\n",
    "#            print(file_name)\n",
    "#            content.insert(0,'sep=,\\n')\n",
    "#        fout.writelines(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise dataframe\n",
    "df_clean = pd.DataFrame(columns=['id', 'name', 'frame', 't', 'FI_corr', 'switch', 'background_CV', 'area', 'area2'])\n",
    "# loop over CSVs\n",
    "for file_name in csv_files:\n",
    "    # load data\n",
    "    name = file_name.split(sep='\\\\')[-1].split(sep='.')[0][7:]\n",
    "    df = pd.read_csv(file_name, skiprows=0)\n",
    "    \n",
    "    # compute stuff\n",
    "    cutoff = comp_cutoff(df['area'].values, diff_crit=50, length_crit=15)\n",
    "    df['switch'] = cutoff\n",
    "    \n",
    "    corr = background_correction(df['FIchannel'].values, df['FIpdms'].values)\n",
    "    \n",
    "    background_cv = stats.variation(df['FIchannel'].values/corr)\n",
    "    df['background_CV'] = background_cv\n",
    "    \n",
    "    # clean FI signal\n",
    "    # combine first/second mother cell\n",
    "    if not cutoff is None:\n",
    "        df['FI_corr'] = np.concatenate([df['FI'].values[:cutoff], df['FI2'].values[cutoff:]])\n",
    "    else: \n",
    "        df['FI_corr'] = df['FI'].values\n",
    "    # background correction\n",
    "    df['FI_corr'] = df['FI_corr'].values/corr\n",
    "\n",
    "    # drop timepoint 151\n",
    "    df = df[df['frame'] != 151]\n",
    "    \n",
    "    \n",
    "    # add rows if background is ok (CV of channel below 0.04)\n",
    "    if background_cv < 0.04:\n",
    "        df_clean = df_clean.append(df[['id', 'name', 'frame', 't', 'FI_corr', 'switch', 'background_CV', 'area', 'area2']])\n",
    "        \n",
    "df_clean.to_csv('../191120_proc/5_data/191120_tracesX.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 2\n",
    "- input tif videos of cropped to seperate channels, with folder for brightfield (BF), GFP fluorescence intensity (FI) and segmentation output from ilastik (SEG) (3 subfolders, respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "folder_path = '../200114_proc/4_gchannel_split' \n",
    "verify_frames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- process videos and output csv table for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over all tifs in folder_path, assume subfolder structure (BF, FI and SEG) and specific filenames\n",
    "BF_folder_path = os.path.join(folder_path, 'BF')\n",
    "BF_list = [i for i in glob.glob(os.path.join(BF_folder_path, '*.tif'))]\n",
    "\n",
    "# first iterate over BF tifs, then open corresponding FI and SEG\n",
    "i = 1\n",
    "interrupt = 1000\n",
    "for path_BF in BF_list:\n",
    "    if i > interrupt:\n",
    "        sys.exit( 0 )\n",
    "    print('\\n%i out of %i' % (i, len(BF_list)))\n",
    "    sample_name = '200114' + path_BF.split(sep='\\\\')[-1][4:-7]\n",
    "    im_fi, im_bf, mask_bin, T = open_3ch(folder_path, path_BF, flip_upside_down=True)\n",
    "    # execute main process\n",
    "    df = analyse_tifs()\n",
    "    df['name'] = str(sample_name)\n",
    "    df['id'] = i\n",
    "    # save CSV\n",
    "    out_path = os.path.join(folder_path, 'CSV', str(sample_name)) + '.csv'\n",
    "    df.to_csv(out_path, index=False)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- open csv tabes of individual channels, process and summarize in single csv table\n",
    "- for this dataset create one csv table containing all channels selected for BF plus one csv table containing channels selected for BF and FI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All fine\n"
     ]
    }
   ],
   "source": [
    "csv_folder_path = '../200114_proc/4_gchannel_split/CSV_select' # CSV_select folder for channels selected for FI\n",
    "csv_files = [i for i in glob.glob(os.path.join(csv_folder_path, '*.csv'))]\n",
    "\n",
    "# check that all the FI vectors are the same length\n",
    "l = []\n",
    "for path in csv_files:\n",
    "    pos = int(path.split(sep='\\\\')[-1][10:12])\n",
    "    table = pd.read_csv(path, skiprows=0)\n",
    "    s = \"Pos %i: Length %i\" % (pos, len(table['FI']))\n",
    "    #print(s)\n",
    "    l.append(len(table['FI']))\n",
    "if l.count(l[0]) == len(l):\n",
    "    print(\"All fine\")\n",
    "else:\n",
    "    print(\"Unequal length\")\n",
    "\n",
    "# time vector\n",
    "t = np.array(range(l[0]))*1/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise dataframe\n",
    "df_clean = pd.DataFrame(columns=['id', 'name', 'frame', 't', 'FI_corr', 'switch', 'background_CV', 'area', 'area2'])\n",
    "# loop over CSVs\n",
    "for file_name in csv_files:\n",
    "    print(file_name)\n",
    "    # load data\n",
    "    name = file_name.split(sep='\\\\')[-1].split(sep='.')[0][7:]\n",
    "    df = pd.read_csv(file_name, skiprows=0)\n",
    "    df['t'] = t\n",
    "    # compute stuff\n",
    "    cutoff = comp_cutoff(df['area'].values, diff_crit=50, length_crit=15)\n",
    "    df['switch'] = cutoff\n",
    "    \n",
    "    corr = background_correction(df['FIchannel'].values, df['FIpdms'].values, pdms_only=True)\n",
    "    \n",
    "    background_cv = stats.variation(df['FIchannel'].values/corr)\n",
    "    df['background_CV'] = background_cv\n",
    "    \n",
    "    # clean FI signal\n",
    "    # combine first/second mother cell\n",
    "    if not cutoff is None:\n",
    "        df['FI_corr'] = np.concatenate([df['FI'].values[:cutoff], df['FI2'].values[cutoff:]])\n",
    "    else: \n",
    "        df['FI_corr'] = df['FI'].values\n",
    "    # background correction\n",
    "    df['FI_corr'] = df['FI_corr'].values/corr\n",
    "\n",
    "    # drop timepoint 151\n",
    "    df = df[df['frame'] != 136]\n",
    "    \n",
    "    df_clean = df_clean.append(df[['id', 'name', 'frame', 't', 'FI_corr', 'switch', 'background_CV', 'area', 'area2']])\n",
    "        \n",
    "df_clean.to_csv('../200114_proc/200114_traces_select.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude some more traces from selection\n",
    "df = pd.read_csv('../200114_proc/200114_traces_select.csv')\n",
    "exclude = [17, 20, 40, 53, 3, 51]\n",
    "for e in exclude:\n",
    "    df.drop(df[df['id'] == e].index, inplace=True)\n",
    "df.to_csv('../200114_proc/200114_traces_select_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder_path = '../200114_proc/4_gchannel_split/CSV' # all channels\n",
    "\n",
    "# initialise dataframe\n",
    "df_clean = pd.DataFrame(columns=['id', 'name', 'frame', 't', 'FI_corr', 'switch', 'background_CV', 'area', 'area2'])\n",
    "# loop over CSVs\n",
    "csv_files_s = [i for i in glob.glob(os.path.join(csv_folder_path, '*.csv'))]\n",
    "for file_name in csv_files_s:\n",
    "    print(file_name)\n",
    "    # load data\n",
    "    name = file_name.split(sep='\\\\')[-1].split(sep='.')[0][7:]\n",
    "    df = pd.read_csv(file_name, skiprows=0)\n",
    "    df['t'] = t\n",
    "    # compute stuff\n",
    "    cutoff = comp_cutoff(df['area'].values, diff_crit=50, length_crit=15)\n",
    "    df['switch'] = cutoff\n",
    "    \n",
    "    corr = background_correction(df['FIchannel'].values, df['FIpdms'].values, pdms_only=True)\n",
    "    \n",
    "    background_cv = stats.variation(df['FIchannel'].values/corr)\n",
    "    df['background_CV'] = background_cv\n",
    "    \n",
    "    # clean FI signal\n",
    "    # combine first/second mother cell\n",
    "    if not cutoff is None:\n",
    "        df['FI_corr'] = np.concatenate([df['FI'].values[:cutoff], df['FI2'].values[cutoff:]])\n",
    "    else: \n",
    "        df['FI_corr'] = df['FI'].values\n",
    "    # background correction\n",
    "    df['FI_corr'] = df['FI_corr'].values/corr\n",
    "\n",
    "    # drop timepoint 151\n",
    "    df = df[df['frame'] != 136]\n",
    "    \n",
    "    df_clean = df_clean.append(df[['id', 'name', 'frame', 't', 'FI_corr', 'switch', 'background_CV', 'area', 'area2']])\n",
    "        \n",
    "df_clean.to_csv('../200114_proc/200114_traces_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 3\n",
    "- control experiment, with aTc added\n",
    "- acquisition freeze after t216, discard later timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "folder_path = '../200617_channels' \n",
    "verify_frames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- process videos and output csv table for each channel\n",
    "- (rename segmentation suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 out of 60\n",
      "No mother cell found for file 20011417_02_gch4 frame 218 108\n",
      "2 out of 60\n",
      "No 2nd mother cell found for file 20011417_03_gch7 frame 218\n",
      "3 out of 60\n",
      "No 2nd mother cell found for file 20011417_03_gch9 frame 218\n",
      "4 out of 60\n",
      "\n",
      "5 out of 60\n",
      "No mother cell found for file 20011417_04_gch5 frame 218 15\n",
      "6 out of 60\n",
      "No 2nd mother cell found for file 20011417_05_gch2 frame 218\n",
      "7 out of 60\n",
      "No 2nd mother cell found for file 20011417_06_gch11 frame 132\n",
      "8 out of 60\n",
      "No 2nd mother cell found for file 20011417_06_gch2 frame 218\n",
      "9 out of 60\n",
      "No mother cell found for file 20011417_08_gch1 frame 218 217\n",
      "10 out of 60\n",
      "No 2nd mother cell found for file 20011417_09_gch1 frame 183\n",
      "11 out of 60\n",
      "No 2nd mother cell found for file 20011417_09_gch7 frame 218\n",
      "12 out of 60\n",
      "No 2nd mother cell found for file 20011417_10_gch11 frame 180\n",
      "13 out of 60\n",
      "No mother cell found for file 20011417_10_gch1 frame 218 197\n",
      "14 out of 60\n",
      "No 2nd mother cell found for file 20011417_10_gch3 frame 218\n",
      "15 out of 60\n",
      "No 2nd mother cell found for file 20011417_10_gch6 frame 211\n",
      "16 out of 60\n",
      "No 2nd mother cell found for file 20011417_10_gch8 frame 218\n",
      "17 out of 60\n",
      "No 2nd mother cell found for file 20011417_11_gch3 frame 192\n",
      "18 out of 60\n",
      "No 2nd mother cell found for file 20011417_11_gch6 frame 218\n",
      "19 out of 60\n",
      "No mother cell found for file 20011417_11_gch8 frame 218 144\n",
      "20 out of 60\n",
      "\n",
      "21 out of 60\n",
      "No mother cell found for file 20011417_12_gch6 frame 218 217\n",
      "22 out of 60\n",
      "No 2nd mother cell found for file 20011417_13_gch11 frame 218\n",
      "23 out of 60\n",
      "No 2nd mother cell found for file 20011417_13_gch3 frame 47\n",
      "24 out of 60\n",
      "No 2nd mother cell found for file 20011417_13_gch9 frame 212\n",
      "25 out of 60\n",
      "\n",
      "26 out of 60\n",
      "\n",
      "27 out of 60\n",
      "No 2nd mother cell found for file 20011417_15_gch8 frame 169\n",
      "28 out of 60\n",
      "No 2nd mother cell found for file 20011417_16_gch10 frame 218\n",
      "29 out of 60\n",
      "No mother cell found for file 20011417_16_gch8 frame 218 213\n",
      "30 out of 60\n",
      "No mother cell found for file 20011417_17_gch4 frame 218 195\n",
      "31 out of 60\n",
      "\n",
      "32 out of 60\n",
      "No 2nd mother cell found for file 20011417_18_gch10 frame 208\n",
      "33 out of 60\n",
      "No 2nd mother cell found for file 20011417_19_gch11 frame 216\n",
      "34 out of 60\n",
      "No mother cell found for file 20011417_20_gch10 frame 218 133\n",
      "35 out of 60\n",
      "No 2nd mother cell found for file 20011417_20_gch6 frame 150\n",
      "36 out of 60\n",
      "No 2nd mother cell found for file 20011417_21_gch2 frame 216\n",
      "37 out of 60\n",
      "No 2nd mother cell found for file 20011417_21_gch6 frame 174\n",
      "38 out of 60\n",
      "No mother cell found for file 20011417_22_gch2 frame 218 214\n",
      "39 out of 60\n",
      "No 2nd mother cell found for file 20011417_22_gch6 frame 218\n",
      "40 out of 60\n",
      "No 2nd mother cell found for file 20011417_23_gch3 frame 114\n",
      "41 out of 60\n",
      "No mother cell found for file 20011417_23_gch6 frame 218 204\n",
      "42 out of 60\n",
      "No mother cell found for file 20011417_24_gch11 frame 218 217\n",
      "43 out of 60\n",
      "No 2nd mother cell found for file 20011417_24_gch8 frame 182\n",
      "44 out of 60\n",
      "\n",
      "45 out of 60\n",
      "No 2nd mother cell found for file 20011417_26_gch4 frame 218\n",
      "46 out of 60\n",
      "No 2nd mother cell found for file 20011417_26_gch8 frame 165\n",
      "47 out of 60\n",
      "No mother cell found for file 20011417_28_gch10 frame 218 170\n",
      "48 out of 60\n",
      "No 2nd mother cell found for file 20011417_28_gch6 frame 173\n",
      "49 out of 60\n",
      "No 2nd mother cell found for file 20011417_29_gch2 frame 211\n",
      "50 out of 60\n",
      "No 2nd mother cell found for file 20011417_30_gch6 frame 167\n",
      "51 out of 60\n",
      "No mother cell found for file 20011417_31_gch2 frame 218 187\n",
      "52 out of 60\n",
      "No mother cell found for file 20011417_31_gch4 frame 218 139\n",
      "53 out of 60\n",
      "No mother cell found for file 20011417_32_gch10 frame 218 195\n",
      "54 out of 60\n",
      "No mother cell found for file 20011417_32_gch3 frame 218 167\n",
      "55 out of 60\n",
      "No 2nd mother cell found for file 20011417_32_gch6 frame 218\n",
      "56 out of 60\n",
      "No 2nd mother cell found for file 20011417_33_gch3 frame 52\n",
      "57 out of 60\n",
      "No 2nd mother cell found for file 20011417_33_gch4 frame 157\n",
      "58 out of 60\n",
      "\n",
      "59 out of 60\n",
      "No 2nd mother cell found for file 20011417_35_gch7 frame 128\n",
      "60 out of 60\n"
     ]
    }
   ],
   "source": [
    "# iterate over all tifs in folder_path, assume subfolder structure (BF, FI and SEG) and specific filenames\n",
    "BF_folder_path = os.path.join(folder_path, 'BF')\n",
    "BF_list = [i for i in glob.glob(os.path.join(BF_folder_path, '*.tif'))]\n",
    "\n",
    "# first iterate over BF tifs, then open corresponding FI and SEG\n",
    "i = 1\n",
    "interrupt = 1000\n",
    "for path_BF in BF_list:\n",
    "    if i > interrupt:\n",
    "        sys.exit( 0 )\n",
    "    print('\\n%i out of %i' % (i, len(BF_list)))\n",
    "    sample_name = '200114' + path_BF.split(sep='\\\\')[-1][4:-7]\n",
    "    im_fi, im_bf, mask_bin, T = open_3ch(folder_path, path_BF, flip_upside_down=False)\n",
    "    # execute main process\n",
    "    df = analyse_tifs()\n",
    "    df['name'] = str(sample_name)\n",
    "    df['id'] = i\n",
    "    # save CSV\n",
    "    out_path = os.path.join(folder_path, 'CSV', str(sample_name)) + '.csv'\n",
    "    df.to_csv(out_path, index=False)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- open csv tabes of individual channels, process and summarize in single csv table\n",
    "- cutoff after t216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All fine\n"
     ]
    }
   ],
   "source": [
    "csv_folder_path = '../200617_channels/CSV' # CSV_select folder for channels selected for FI\n",
    "csv_files = [i for i in glob.glob(os.path.join(csv_folder_path, '*.csv'))]\n",
    "\n",
    "# check that all the FI vectors are the same length\n",
    "l = []\n",
    "for path in csv_files:\n",
    "    pos = int(path.split(sep='\\\\')[-1][9:11])\n",
    "    table = pd.read_csv(path, skiprows=0)\n",
    "    s = \"Pos %i: Length %i\" % (pos, len(table['FI']))\n",
    "    #print(s)\n",
    "    l.append(len(table['FI']))\n",
    "if l.count(l[0]) == len(l):\n",
    "    print(\"All fine\")\n",
    "else:\n",
    "    print(\"Unequal length\")\n",
    "\n",
    "# time vector\n",
    "t = np.array(range(l[0]))*1/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:157: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "# initialise dataframe\n",
    "df_clean = pd.DataFrame(columns=['id', 'name', 'frame', 't', 'FI_corr', 'switch', 'background_CV', 'area', 'area2'])\n",
    "# loop over CSVs\n",
    "for file_name in csv_files:\n",
    "    # load data\n",
    "    name = file_name.split(sep='\\\\')[-1].split(sep='.')[0][7:]\n",
    "    df = pd.read_csv(file_name, skiprows=0)\n",
    "    \n",
    "    # compute stuff\n",
    "    cutoff = comp_cutoff(df['area'].values, diff_crit=50, length_crit=15)\n",
    "    df['switch'] = cutoff\n",
    "    \n",
    "    corr = background_correction(df['FIchannel'].values, df['FIpdms'].values)\n",
    "    \n",
    "    background_cv = stats.variation(df['FIchannel'].values/corr)\n",
    "    df['background_CV'] = background_cv\n",
    "    \n",
    "    # clean FI signal\n",
    "    # combine first/second mother cell\n",
    "    if not cutoff is None:\n",
    "        df['FI_corr'] = np.concatenate([df['FI'].values[:cutoff], df['FI2'].values[cutoff:]])\n",
    "    else: \n",
    "        df['FI_corr'] = df['FI'].values\n",
    "    # background correction\n",
    "    df['FI_corr'] = df['FI_corr'].values/corr\n",
    "    \n",
    "    df['t'] = t\n",
    "    \n",
    "    # cut off last three timepoints\n",
    "    df = df[df['frame'] != 218]\n",
    "    df = df[df['frame'] != 217]\n",
    "    df = df[df['frame'] != 216]\n",
    "    \n",
    "    # add rows if background is ok (CV of channel below 0.04)\n",
    "    if background_cv < 0.04:\n",
    "        df_clean = df_clean.append(df[['id', 'name', 'frame', 't', 'FI_corr', 'switch', 'background_CV', 'area', 'area2']])\n",
    "        \n",
    "df_clean.to_csv('../200617_channels/200617_traces.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine datasets for publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {1:'data/191120_traces.csv', 2:'data/200114_traces_select_new.csv', 3:'data/200617_traces.csv'}\n",
    "df_comb = pd.DataFrame()\n",
    "for key in paths.keys():\n",
    "    df = pd.read_csv(paths[key])\n",
    "    df['key'] = key\n",
    "    df_comb = df_comb.append(df, ignore_index=True)\n",
    "\n",
    "df_comb.to_csv('data/dataset_s1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 4 (control experiment repeat)\n",
    "- input tif videos of cropped to seperate channels, with folder for brightfield (BF), GFP fluorescence intensity (FI) and segmentation output from ilastik (SEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "folder_path = '../200721_split' \n",
    "verify_frames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- process videos and output csv table for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 out of 19\n",
      "No mother cell found for file 19112021_02_gch10 frame 296 294\n",
      "2 out of 19\n",
      "No 2nd mother cell found for file 19112021_02_gch11 frame 290\n",
      "3 out of 19\n",
      "No 2nd mother cell found for file 19112021_07_gch1 frame 2\n",
      "4 out of 19\n",
      "No 2nd mother cell found for file 19112021_07_gch3 frame 114\n",
      "5 out of 19\n",
      "\n",
      "6 out of 19\n",
      "\n",
      "7 out of 19\n",
      "\n",
      "8 out of 19\n",
      "\n",
      "9 out of 19\n",
      "No 2nd mother cell found for file 19112021_16_gch7 frame 296\n",
      "10 out of 19\n",
      "No 2nd mother cell found for file 19112021_17_gch10 frame 131\n",
      "11 out of 19\n",
      "No 2nd mother cell found for file 19112021_17_gch9 frame 15\n",
      "12 out of 19\n",
      "\n",
      "13 out of 19\n",
      "\n",
      "14 out of 19\n",
      "\n",
      "15 out of 19\n",
      "\n",
      "16 out of 19\n",
      "\n",
      "17 out of 19\n",
      "No 2nd mother cell found for file 19112021_24_gch11 frame 83\n",
      "18 out of 19\n",
      "No 2nd mother cell found for file 19112021_26_gch11 frame 265\n",
      "19 out of 19\n"
     ]
    }
   ],
   "source": [
    "# iterate over all tifs in folder_path, assume subfolder structure (BF, FI and SEG) and specific filenames\n",
    "BF_folder_path = os.path.join(folder_path, 'BF')\n",
    "BF_list = [i for i in glob.glob(os.path.join(BF_folder_path, '*.tif'))]\n",
    "\n",
    "# first iterate over BF tifs, then open corresponding FI and SEG\n",
    "i = 1\n",
    "interrupt = 1000\n",
    "for path_BF in BF_list:\n",
    "    if i > interrupt:\n",
    "        sys.exit( 0 )\n",
    "    print('\\n%i out of %i' % (i, len(BF_list)))\n",
    "    sample_name = '191120' + path_BF.split(sep='\\\\')[-1][4:-7]\n",
    "    im_fi, im_bf, mask_bin, T = open_3ch(folder_path, path_BF)\n",
    "    # execute main process\n",
    "    df = analyse_tifs()\n",
    "    df['name'] = str(sample_name)\n",
    "    df['id'] = i\n",
    "    # save CSV\n",
    "    out_path = os.path.join(folder_path, 'CSV', str(sample_name)) + '.csv'\n",
    "    df.to_csv(out_path, index=False)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- open csv tabes of individual channels, process and summarize in single csv table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All fine\n"
     ]
    }
   ],
   "source": [
    "csv_folder_path = '../200721_split/CSV' \n",
    "csv_files = [i for i in glob.glob(os.path.join(csv_folder_path, '*.csv'))]\n",
    "\n",
    "# check that all the FI vectors are the same length\n",
    "l = []\n",
    "for path in csv_files:\n",
    "    pos = int(path.split(sep='\\\\')[-1][9:11])\n",
    "    table = pd.read_csv(path, skiprows=0)\n",
    "    s = \"Pos %i: Length %i\" % (pos, len(table['FI']))\n",
    "    #print(s)\n",
    "    l.append(len(table['FI']))\n",
    "if l.count(l[0]) == len(l):\n",
    "    print(\"All fine\")\n",
    "else:\n",
    "    print(\"Unequal length\")\n",
    "\n",
    "# time vector\n",
    "t = np.array(range(l[0]))*1/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sep=, to csv files to open them easily in Excel\n",
    "#print('sep=, added to the following files:')\n",
    "#for file_name in csv_files:\n",
    "#    with open(file_name, 'r') as fin:\n",
    "#        content = fin.read().splitlines(True)\n",
    "#    with open(file_name, 'w') as fout:\n",
    "#        if content[0] != 'sep=,\\n':\n",
    "#            print(file_name)\n",
    "#            content.insert(0,'sep=,\\n')\n",
    "#        fout.writelines(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:157: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "# initialise dataframe\n",
    "df_clean = pd.DataFrame(columns=['id', 'name', 'frame', 't', 'FI_corr', 'switch', 'background_CV', 'area', 'area2'])\n",
    "# loop over CSVs\n",
    "for file_name in csv_files:\n",
    "    # load data\n",
    "    name = file_name.split(sep='\\\\')[-1].split(sep='.')[0][7:]\n",
    "    df = pd.read_csv(file_name, skiprows=0)\n",
    "    \n",
    "    # compute stuff\n",
    "    cutoff = comp_cutoff(df['area'].values, diff_crit=50, length_crit=15)\n",
    "    df['switch'] = cutoff\n",
    "    \n",
    "    corr = background_correction(df['FIchannel'].values, df['FIpdms'].values)\n",
    "    \n",
    "    background_cv = stats.variation(df['FIchannel'].values/corr)\n",
    "    df['background_CV'] = background_cv\n",
    "    \n",
    "    # clean FI signal\n",
    "    # combine first/second mother cell\n",
    "    if not cutoff is None:\n",
    "        df['FI_corr'] = np.concatenate([df['FI'].values[:cutoff], df['FI2'].values[cutoff:]])\n",
    "    else: \n",
    "        df['FI_corr'] = df['FI'].values\n",
    "    # background correction\n",
    "    df['FI_corr'] = df['FI_corr'].values/corr\n",
    "\n",
    "    df['t'] = t\n",
    "    \n",
    "    \n",
    "    # add rows if background is ok (CV of channel below 0.04)\n",
    "    if background_cv < 0.04:\n",
    "        df_clean = df_clean.append(df[['id', 'name', 'frame', 't', 'FI_corr', 'switch', 'background_CV', 'area', 'area2']])\n",
    "        \n",
    "df_clean.to_csv('../200721_split/200721_traces.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
